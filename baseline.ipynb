{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working - Foster Care Analysis\n",
    "This file is a working document for the Foster Care Analysis project. This is not the final version of the project. The final version will be published in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# import function files and environment variables\n",
    "import utils\n",
    "\n",
    "# reload the imports\n",
    "import importlib\n",
    "\n",
    "# Import the plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "\n",
    "# Import the needed ML libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc \n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to the Google Cloud Storage bucket\n",
    "service_account_path = 'GOOGLE_APPLICATION_CREDENTIALS.json'\n",
    "client = storage.Client.from_service_account_json(service_account_path)\n",
    "bucket_name = 'foster-care'\n",
    "bucket = client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Variable Values and Variable Definitions\n",
    "variable_values_df = pd.read_excel(utils.read_cloud_data(bucket, 'FC Variable Values.xlsx')) # Mapping\n",
    "variables_df = pd.read_excel(utils.read_cloud_data(bucket, 'FC Variables.xlsx')) # Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the raw data\n",
    "raw_df_2001 = pd.read_sas(utils.read_cloud_data(bucket, '2001.sas7bdat'), format='sas7bdat') \n",
    "#raw_df_2002 = pd.read_csv(utils.read_cloud_data(bucket, '2002.tab'), sep='\\t', lineterminator='\\n')\n",
    "#raw_df_2003 = pd.read_sas(utils.read_cloud_data(bucket, '2003.sas7bdat'), format='sas7bdat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a function to make the data readable\n",
    "df_2001 = utils.make_readable(raw_df_2001, variable_values_df)\n",
    "#df_2002 = utils.make_readable(raw_df_2002.rename({'FY':'DataYear', 'FIPSCode':'FIPSCODE'}, axis=1), variable_values_df)\n",
    "#df_2003 = utils.make_readable(raw_df_2003.rename({'FY':'DataYear', 'FIPSCode':'FIPSCODE'}, axis=1), variable_values_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_records = pd.concat([df_2001, df_2002, df_2003], axis=0)\n",
    "all_records = df_2001.reset_index(drop=True) # temporarily doing 2001 only so that the code runs faster\n",
    "all_records = utils.remove_nan_values(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the cases where the child has exited foster care\n",
    "exited_df = all_records[all_records['Exited'] == 1]\n",
    "print(exited_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Binary label for if they have reunified\n",
    "exited_df['reunified'] = 0\n",
    "exited_df.loc[(exited_df['Exited'] == 1) & (exited_df['dischargeReason'] == 'Reunified with parent, primary caretaker'), 'reunified'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are are duplicative\n",
    "exited_df = exited_df.drop(columns=['Exited', 'dischargeReason'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_df = exited_df[exited_df['AgeAtEnd'] <= 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the ages of the children in the dataset separated by whether they were reunified or not\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(chart_df, x='AgeAtEnd', hue='reunified', bins=20, kde=True, palette='viridis', multiple='dodge')\n",
    "plt.title('Distribution of Ages of Children in Foster Care')\n",
    "plt.xlabel('Age at Exit')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(np.arange(0, 21, 1))\n",
    "plt.legend(title='Reunified', labels=['Yes', 'No'], loc='upper left')\n",
    "# for p in plt.gca().patches:\n",
    "    # plt.gca().annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for each category in 'reunified'\n",
    "group1 = chart_df[chart_df['reunified'] == chart_df['reunified'].unique()[0]]['AgeAtEnd']\n",
    "group2 = chart_df[chart_df['reunified'] == chart_df['reunified'].unique()[1]]['AgeAtEnd']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the positions of the bars\n",
    "bins = np.histogram_bin_edges(chart_df['AgeAtEnd'], bins=20)\n",
    "width = (bins[1] - bins[0]) * 0.4\n",
    "\n",
    "plt.hist([group1, group2], bins=bins, label=[str(chart_df['reunified'].unique()[0]), str(chart_df['reunified'].unique()[1])], \n",
    "         color=['lightgreen', 'salmon'], edgecolor='black', rwidth=width, align='mid', histtype='bar')\n",
    "\n",
    "plt.legend(title='Reunified')\n",
    "plt.xlabel('Age at End')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Reunified Status by Age')\n",
    "\n",
    "plt.xticks(bins.round(2))\n",
    "plt.xlim([bins.min(), bins.max()])  \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot age v % that reunified\n",
    "age_reunified = chart_df.groupby('AgeAtEnd')['reunified'].mean()\n",
    "age_reunified.plot()\n",
    "plt.title('Age v % Reunified')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('% Reunified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = chart_df.groupby(['reunified', 'Sex']).size().unstack()\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ind = np.arange(len(count_matrix))\n",
    "width = 0.2 # the width of the bars\n",
    "\n",
    "# Plotting the bars\n",
    "bars1 = ax.bar(ind - width, count_matrix['Male'], width, label='Male', color='skyblue', edgecolor='black')\n",
    "bars2 = ax.bar(ind, count_matrix['Female'], width, label='Female', color='salmon', edgecolor='black')\n",
    "bars3 = ax.bar(ind + width, count_matrix['DNG'], width, label='DNG', color='grey', edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Reunified Status')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_title('Counts by Sex and Reunified Status')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(count_matrix.index)\n",
    "ax.legend()\n",
    "\n",
    "ax.bar_label(bars1, padding=3)\n",
    "ax.bar_label(bars2, padding=3)\n",
    "ax.bar_label(bars3, padding=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=\"Sex\", y=\"AgeAtEnd\", hue=\"reunified\", data=chart_df, palette=\"muted\", split=True)\n",
    "\n",
    "plt.title('Distribution of Age and Gender by Reunification Status')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Age')\n",
    "plt.legend(title='Reunified Status')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train-Validation-Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data randomly to avoid any biases\n",
    "exited_df = exited_df.sample(frac = 1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into three sections: training at 60%, validation at 20%, and testing at 20%\n",
    "ml_data_df = exited_df.drop(['DataYear', 'RecNumbr', 'age2021', 'caseGoal', 'AgeAtStart', 'AgedOut'], axis=1)\n",
    "ml_df = pd.get_dummies(ml_data_df, columns=['State', 'FIPSCode', 'Sex', 'removalManner', 'currentPlacementSetting', 'caretakerFamilyStructure', 'fosterFamilyStructure',  'raceEthnicity', 'diagnosedDisability', 'AgeAdopt', 'everAdopted', 'OutOfStatePlacement']) \n",
    "\n",
    "X = ml_df.drop('reunified', axis=1)  # Features\n",
    "y = ml_df['reunified']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the baseline for the training dataset \n",
    "print(f\"Not Reunified in Training Data: {y_train.value_counts()[0]}\")\n",
    "print(f\"Reunified in Training Data: {y_train.value_counts()[1]}\")\n",
    "baseline = y_train.value_counts()[1] / len(y_train)\n",
    "print(f\"\\nPercentage Reunified, Training Baseline: {round(baseline*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the baseline loss for the training dataset\n",
    "\n",
    "def log_loss(Y_true, Y_pred):\n",
    "  \"\"\"Returns the binary log loss for a list of labels and predictions.\n",
    "  \n",
    "  Args:\n",
    "    Y_true: A list of (true) labels (0 or 1)\n",
    "    Y_pred: A list of corresponding predicted probabilities\n",
    "\n",
    "  Returns:\n",
    "    Binary log loss\n",
    "  \"\"\"\n",
    "  loss = -np.mean(Y_true * np.log(Y_pred) + (1 - Y_true) * np.log(1 - Y_pred))\n",
    "  return loss\n",
    "\n",
    "# Use the log_loss function to evaluate our baseline on the train, validation, and test dataset using the average of reunified as our predicted probability.\n",
    "\n",
    "train_loss = log_loss(y_train, baseline)\n",
    "val_loss = log_loss(y_val, baseline)\n",
    "test_loss = log_loss(y_test, baseline)\n",
    "\n",
    "print(\"Log Loss for Baseline on Training Dataset:\", train_loss)\n",
    "print(\"Log Loss for Baseline on Validation Dataset:\", val_loss)\n",
    "print(\"Log Loss for Baseline on Test Dataset:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL ABOVE CODE IS SET FOR MODEL TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "feature_importances[:15].plot(kind='bar', figsize=(6, 3))\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_proba = rf.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  y_pred_proba)\n",
    "auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Pick a single tree from the forest\n",
    "single_tree = rf.estimators_[0]\n",
    "\n",
    "plt.figure(figsize=(60,30))\n",
    "plot_tree(single_tree, filled=True, feature_names=X.columns, max_depth=4, proportion=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert the datasets to DMatrix data structure (optional step for improved performance)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Specify model training parameters\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss'  # You can change this to 'auc' or other relevant metrics\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_rounds = 100\n",
    "bst = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_proba = bst.predict(dtest)\n",
    "y_pred = [1 if x > 0.5 else 0 for x in y_pred_proba]  # Convert probabilities to binary output\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier()\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(xgb_model, param_grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameters and score\n",
    "# print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = np.array(X_train['AgeAtEnd'])[10:20]\n",
    "print(\"Ages:\", age)\n",
    "\n",
    "age_bins = [0, 5, 10, 15, 20]\n",
    "age_binned = tf.keras.layers.Discretization(bin_boundaries=age_bins)(age)\n",
    "print(\"Age Bins:\", age_binned)\n",
    "\n",
    "age_id = tf.keras.layers.IntegerLookup(vocabulary=np.arange(0, len(age_bins)+1), output_mode='one_hot')(age_binned)\n",
    "print('Ages as one-hot:', age_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Clear session and remove randomness.\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    age = tf.keras.layers.Input(shape=(1,), dtype=tf.float32, name='Age')\n",
    "    sex = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='Sex')\n",
    "\n",
    "    age_bins = [0, 5, 10, 15, 20, 30]\n",
    "    age_binned = tf.keras.layers.Discretization(bin_boundaries=age_bins)(age)\n",
    "    age_id = tf.keras.layers.IntegerLookup(\n",
    "        vocabulary=np.arange(0, len(age_bins)+1),\n",
    "        output_mode='one_hot')(age_binned)\n",
    "    \n",
    "    sex_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=['Male', 'Female', 'DNG'], output_mode='one_hot')(sex)\n",
    "    \n",
    "    features = tf.keras.layers.Concatenate()([age_id, sex_id])\n",
    "\n",
    "    dense = tf.keras.layers.Dense(\n",
    "        units=12, activation='tanh', name='hidden1')(features)\n",
    "\n",
    "    reunified = tf.keras.layers.Dense(\n",
    "        units=1, activation='sigmoid', name='reunified')(dense)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[age, sex], \n",
    "                           outputs=reunified, \n",
    "                           name='Foster')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "history = model.fit(\n",
    "    x = {\n",
    "        'Age': ml_data_df['AgeAtEnd'], \n",
    "        'Sex': ml_data_df['Sex']\n",
    "        },\n",
    "    y = ml_data_df['reunified'],\n",
    "    validation_data=(\n",
    "        {\n",
    "            'Age': ml_data_df['AgeAtEnd'], \n",
    "            'Sex': ml_data_df['Sex']\n",
    "        },\n",
    "        ml_data_df['reunified']),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Concatenate - Accuracy: 0.5439\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foster_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
